{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install langgraph langchain-groq langchain-core requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymvYfXsUZSqP",
        "outputId": "3e52ac5d-f501-4595-af3b-f56639b56b16"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (0.6.7)\n",
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.12/dist-packages (0.3.8)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (0.3.75)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.1.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.6.4)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: groq<1,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from langchain-groq) (0.31.1)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.27)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Literal, TypedDict\n",
        "from langchain_groq import ChatGroq\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "import requests\n",
        "import json\n",
        "import re\n",
        "# Set your API keys\n",
        "os.environ[\"GROQ_API_KEY\"] = \"\"\n",
        "os.environ[\"WEATHER_API_KEY\"] = \"\"\n",
        "\n",
        "# Define the state\n",
        "class AgentState(TypedDict):\n",
        "    messages: list\n",
        "    next_agent: Literal[\"weather_agent\", \"python_agent\", \"coordinator\", \"end\"] = \"coordinator\"\n",
        "\n",
        "# Initialize Groq LLM\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.1\n",
        ")\n",
        "\n",
        "# Weather Agent\n",
        "def weather_agent(state: AgentState):\n",
        "    \"\"\"Agent that fetches weather data from weatherapi.com\"\"\"\n",
        "    try:\n",
        "        # Extract location using more robust pattern matching\n",
        "        last_message = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
        "\n",
        "        # Look for location patterns\n",
        "        location_patterns = [\n",
        "            r\"weather in (.+?)(?:\\?|$)\",\n",
        "            r\"weather for (.+?)(?:\\?|$)\",\n",
        "            r\"temperature in (.+?)(?:\\?|$)\",\n",
        "            r\"forecast for (.+?)(?:\\?|$)\"\n",
        "        ]\n",
        "\n",
        "        location = None\n",
        "        for pattern in location_patterns:\n",
        "            match = re.search(pattern, last_message, re.IGNORECASE)\n",
        "            if match:\n",
        "                location = match.group(1).strip()\n",
        "                break\n",
        "\n",
        "        # If no pattern matched, try to extract the last word as location\n",
        "        if not location:\n",
        "            words = last_message.split()\n",
        "            if len(words) > 2:\n",
        "                location = words[-1].rstrip('?.!')\n",
        "\n",
        "        # Default to London if no location found\n",
        "        if not location:\n",
        "            location = \"London\"\n",
        "\n",
        "        # Call WeatherAPI\n",
        "        api_key = os.environ[\"WEATHER_API_KEY\"]\n",
        "        url = f\"http://api.weatherapi.com/v1/current.json?key={api_key}&q={location}&aqi=no\"\n",
        "\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            weather_info = {\n",
        "                \"location\": data[\"location\"][\"name\"],\n",
        "                \"country\": data[\"location\"][\"country\"],\n",
        "                \"temperature\": data[\"current\"][\"temp_c\"],\n",
        "                \"condition\": data[\"current\"][\"condition\"][\"text\"],\n",
        "                \"humidity\": data[\"current\"][\"humidity\"],\n",
        "                \"wind_speed\": data[\"current\"][\"wind_kph\"]\n",
        "            }\n",
        "\n",
        "            response_text = f\"\"\"Weather in {weather_info['location']}, {weather_info['country']}:\n",
        "- Temperature: {weather_info['temperature']}Â°C\n",
        "- Condition: {weather_info['condition']}\n",
        "- Humidity: {weather_info['humidity']}%\n",
        "- Wind Speed: {weather_info['wind_speed']} km/h\"\"\"\n",
        "\n",
        "        else:\n",
        "            response_text = f\"Error fetching weather data: {data.get('error', {}).get('message', 'Unknown error')}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        response_text = f\"Error in weather agent: {str(e)}\"\n",
        "\n",
        "    return {\n",
        "        \"messages\": [AIMessage(content=response_text)],\n",
        "        \"next_agent\": \"end\"\n",
        "    }\n",
        "\n",
        "# Python REPL Agent\n",
        "def python_agent(state: AgentState):\n",
        "    \"\"\"Agent that executes Python code and returns results\"\"\"\n",
        "    try:\n",
        "        # Extract the user's request\n",
        "        last_message = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
        "\n",
        "        # Use LLM to generate appropriate Python code\n",
        "        prompt = f\"\"\"The user asked: \"{last_message}\"\n",
        "\n",
        "Please generate appropriate Python code to fulfill this request.\n",
        "Return ONLY the Python code without any explanations or markdown formatting.\n",
        "If the request is not suitable for Python code execution, return an empty string.\"\"\"\n",
        "\n",
        "        response = llm.invoke([HumanMessage(content=prompt)])\n",
        "        code = response.content.strip()\n",
        "\n",
        "        # Remove markdown code blocks if present\n",
        "        if \"```python\" in code:\n",
        "            code = code.split(\"```python\")[1].split(\"```\")[0].strip()\n",
        "        elif \"```\" in code:\n",
        "            code = code.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "        # If no code was generated or request not suitable for Python\n",
        "        if not code or \"I cannot\" in code or \"I can't\" in code:\n",
        "            return {\n",
        "                \"messages\": [AIMessage(content=\"I'm not able to generate appropriate Python code for this request.\")],\n",
        "                \"next_agent\": \"end\"\n",
        "            }\n",
        "\n",
        "        # Execute the code safely (with restrictions)\n",
        "        allowed_modules = [\"math\", \"datetime\", \"random\", \"json\", \"collections\"]\n",
        "        exec_globals = {}\n",
        "\n",
        "        for module in allowed_modules:\n",
        "            try:\n",
        "                exec_globals[module] = __import__(module)\n",
        "            except ImportError:\n",
        "                pass\n",
        "\n",
        "        # Execute the code and capture output\n",
        "        try:\n",
        "            # Redirect stdout to capture print statements\n",
        "            from io import StringIO\n",
        "            import sys\n",
        "\n",
        "            old_stdout = sys.stdout\n",
        "            sys.stdout = captured_output = StringIO()\n",
        "\n",
        "            exec(code, exec_globals)\n",
        "\n",
        "            sys.stdout = old_stdout\n",
        "            result = captured_output.getvalue()\n",
        "\n",
        "            if not result:\n",
        "                result = \"Code executed successfully (no output)\"\n",
        "\n",
        "        except Exception as e:\n",
        "            result = f\"Error executing code: {str(e)}\"\n",
        "\n",
        "        response_text = f\"I executed the following Python code:\\n```python\\n{code}\\n```\\nResult:\\n{result}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        response_text = f\"Error in Python agent: {str(e)}\"\n",
        "\n",
        "    return {\n",
        "        \"messages\": [AIMessage(content=response_text)],\n",
        "        \"next_agent\": \"end\"\n",
        "    }\n",
        "\n",
        "# Coordinator Agent\n",
        "def coordinator_agent(state: AgentState):\n",
        "    \"\"\"Agent that decides which specialized agent to invoke\"\"\"\n",
        "    last_message = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
        "\n",
        "    # Use LLM to decide which agent to call with better prompting\n",
        "    prompt = f\"\"\"Analyze the user's request and decide which agent should handle it:\n",
        "\n",
        "User request: \"{last_message}\"\n",
        "\n",
        "Available agents:\n",
        "1. weather_agent - for weather-related queries (temperature, forecast, weather conditions, climate)\n",
        "2. python_agent - for calculations, data processing, math problems, or any request that can be solved with code\n",
        "\n",
        "Consider these examples:\n",
        "- \"What's the weather in Paris?\" â weather_agent\n",
        "- \"Calculate 5 * 8\" â python_agent\n",
        "- \"What's the temperature in Tokyo?\" â weather_agent\n",
        "- \"Write code to calculate factorial of 5\" â python_agent\n",
        "- \"How humid is it in London?\" â weather_agent\n",
        "- \"Solve 2x + 5 = 15\" â python_agent\n",
        "\n",
        "Respond with ONLY the name of the appropriate agent: either \"weather_agent\" or \"python_agent\"\n",
        "If the request doesn't match either, respond with \"end\".\"\"\"\n",
        "\n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    next_agent = response.content.strip().lower()\n",
        "\n",
        "    # Validate the response\n",
        "    if next_agent not in [\"weather_agent\", \"python_agent\"]:\n",
        "        next_agent = \"end\"\n",
        "\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"],\n",
        "        \"next_agent\": next_agent\n",
        "    }\n",
        "\n",
        "# Build the graph\n",
        "def build_agent_graph():\n",
        "    workflow = StateGraph(AgentState)\n",
        "\n",
        "    # Add nodes\n",
        "    workflow.add_node(\"coordinator\", coordinator_agent)\n",
        "    workflow.add_node(\"weather_agent\", weather_agent)\n",
        "    workflow.add_node(\"python_agent\", python_agent)\n",
        "\n",
        "    # Set entry point\n",
        "    workflow.set_entry_point(\"coordinator\")\n",
        "\n",
        "    # Add edges\n",
        "    workflow.add_conditional_edges(\n",
        "        \"coordinator\",\n",
        "        lambda state: state[\"next_agent\"],\n",
        "        {\n",
        "            \"weather_agent\": \"weather_agent\",\n",
        "            \"python_agent\": \"python_agent\",\n",
        "            \"end\": END\n",
        "        }\n",
        "    )\n",
        "\n",
        "    workflow.add_edge(\"weather_agent\", END)\n",
        "    workflow.add_edge(\"python_agent\", END)\n",
        "\n",
        "    return workflow.compile()\n",
        "\n",
        "# Create the graph\n",
        "agent_graph = build_agent_graph()\n",
        "\n",
        "# Function to run the agent system\n",
        "def run_agent_system(user_input: str):\n",
        "    \"\"\"Run the agent system with user input\"\"\"\n",
        "    initial_state = {\n",
        "        \"messages\": [HumanMessage(content=user_input)],\n",
        "        \"next_agent\": \"coordinator\"\n",
        "    }\n",
        "\n",
        "    result = agent_graph.invoke(initial_state)\n",
        "    return result[\"messages\"][-1].content\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Test examples\n",
        "    test_queries = [\n",
        "        \"What's the weather in Sydney?\",\n",
        "        \"Can you calculate 5 * 8 for me?\",\n",
        "        \"What's the temperature in Tokyo?\",\n",
        "        \"Write Python code to calculate factorial of 5\",\n",
        "        \"How humid is it in London?\",\n",
        "        \"Solve for x: 2x + 5 = 15\"\n",
        "    ]\n",
        "\n",
        "    for query in test_queries:\n",
        "        print(f\"\\nUser: {query}\")\n",
        "        response = run_agent_system(query)\n",
        "        print(f\"Response: {response}\")\n",
        "        print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALT7czCzadVj",
        "outputId": "41ec33aa-395b-45bb-d8e2-21cfec4b4e30"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User: What's the weather in Sydney?\n",
            "Response: Weather in Sydney, Australia:\n",
            "- Temperature: 14.0Â°C\n",
            "- Condition: Light rain\n",
            "- Humidity: 77%\n",
            "- Wind Speed: 28.8 km/h\n",
            "--------------------------------------------------\n",
            "\n",
            "User: Can you calculate 5 * 8 for me?\n",
            "Response: I executed the following Python code:\n",
            "```python\n",
            "print(5 * 8)\n",
            "```\n",
            "Result:\n",
            "40\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "User: What's the temperature in Tokyo?\n",
            "Response: Weather in Tokyo, Japan:\n",
            "- Temperature: 23.3Â°C\n",
            "- Condition: Partly cloudy\n",
            "- Humidity: 61%\n",
            "- Wind Speed: 24.8 km/h\n",
            "--------------------------------------------------\n",
            "\n",
            "User: Write Python code to calculate factorial of 5\n",
            "Response: I executed the following Python code:\n",
            "```python\n",
            "def factorial(n):\n",
            "    if n == 0:\n",
            "        return 1\n",
            "    else:\n",
            "        return n * factorial(n-1)\n",
            "\n",
            "print(factorial(5))\n",
            "```\n",
            "Result:\n",
            "120\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "User: How humid is it in London?\n",
            "Response: Weather in London, United Kingdom:\n",
            "- Temperature: 11.3Â°C\n",
            "- Condition: Sunny\n",
            "- Humidity: 71%\n",
            "- Wind Speed: 17.6 km/h\n",
            "--------------------------------------------------\n",
            "\n",
            "User: Solve for x: 2x + 5 = 15\n",
            "Response: I executed the following Python code:\n",
            "```python\n",
            "from sympy import symbols, Eq, solve\n",
            "\n",
            "x = symbols('x')\n",
            "equation = Eq(2*x + 5, 15)\n",
            "solution = solve(equation, x)\n",
            "print(solution)\n",
            "```\n",
            "Result:\n",
            "[5]\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Literal, TypedDict\n",
        "from langchain_groq import ChatGroq\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "import requests\n",
        "import json\n",
        "import re\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"\"\n",
        "os.environ[\"WEATHER_API_KEY\"] = \"\"\n",
        "# Define the state\n",
        "class AgentState(TypedDict):\n",
        "    messages: list\n",
        "    next_agent: Literal[\"weather_agent\", \"python_agent\", \"coordinator\", \"end\"] = \"coordinator\"\n",
        "\n",
        "# Initialize Groq LLM\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.1\n",
        ")\n",
        "\n",
        "# Weather Agent\n",
        "def weather_agent(state: AgentState):\n",
        "    \"\"\"Agent that fetches weather data from weatherapi.com\"\"\"\n",
        "    try:\n",
        "        # Extract location using more robust pattern matching\n",
        "        last_message = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
        "\n",
        "        # Look for location patterns\n",
        "        location_patterns = [\n",
        "            r\"weather in (.+?)(?:\\?|$)\",\n",
        "            r\"weather for (.+?)(?:\\?|$)\",\n",
        "            r\"temperature in (.+?)(?:\\?|$)\",\n",
        "            r\"forecast for (.+?)(?:\\?|$)\"\n",
        "        ]\n",
        "\n",
        "        location = None\n",
        "        for pattern in location_patterns:\n",
        "            match = re.search(pattern, last_message, re.IGNORECASE)\n",
        "            if match:\n",
        "                location = match.group(1).strip()\n",
        "                break\n",
        "\n",
        "        # If no pattern matched, try to extract the last word as location\n",
        "        if not location:\n",
        "            words = last_message.split()\n",
        "            if len(words) > 2:\n",
        "                location = words[-1].rstrip('?.!')\n",
        "\n",
        "        # Default to London if no location found\n",
        "        if not location:\n",
        "            location = \"London\"\n",
        "\n",
        "        # Call WeatherAPI\n",
        "        api_key = os.environ[\"WEATHER_API_KEY\"]\n",
        "        url = f\"http://api.weatherapi.com/v1/current.json?key={api_key}&q={location}&aqi=no\"\n",
        "\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            weather_info = {\n",
        "                \"location\": data[\"location\"][\"name\"],\n",
        "                \"country\": data[\"location\"][\"country\"],\n",
        "                \"temperature\": data[\"current\"][\"temp_c\"],\n",
        "                \"condition\": data[\"current\"][\"condition\"][\"text\"],\n",
        "                \"humidity\": data[\"current\"][\"humidity\"],\n",
        "                \"wind_speed\": data[\"current\"][\"wind_kph\"]\n",
        "            }\n",
        "\n",
        "            response_text = f\"\"\"Weather in {weather_info['location']}, {weather_info['country']}:\n",
        "- Temperature: {weather_info['temperature']}Â°C\n",
        "- Condition: {weather_info['condition']}\n",
        "- Humidity: {weather_info['humidity']}%\n",
        "- Wind Speed: {weather_info['wind_speed']} km/h\"\"\"\n",
        "\n",
        "        else:\n",
        "            response_text = f\"Error fetching weather data: {data.get('error', {}).get('message', 'Unknown error')}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        response_text = f\"Error in weather agent: {str(e)}\"\n",
        "\n",
        "    return {\n",
        "        \"messages\": [AIMessage(content=response_text)],\n",
        "        \"next_agent\": \"end\"\n",
        "    }\n",
        "\n",
        "# Python REPL Agent\n",
        "def python_agent(state: AgentState):\n",
        "    \"\"\"Agent that executes Python code and returns results\"\"\"\n",
        "    try:\n",
        "        # Extract the user's request\n",
        "        last_message = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
        "\n",
        "        # Use LLM to generate appropriate Python code\n",
        "        prompt = f\"\"\"The user asked: \"{last_message}\"\n",
        "\n",
        "Please generate appropriate Python code to fulfill this request.\n",
        "Return ONLY the Python code without any explanations or markdown formatting.\n",
        "If the request is not suitable for Python code execution, return an empty string.\"\"\"\n",
        "\n",
        "        response = llm.invoke([HumanMessage(content=prompt)])\n",
        "        code = response.content.strip()\n",
        "\n",
        "        # Remove markdown code blocks if present\n",
        "        if \"```python\" in code:\n",
        "            code = code.split(\"```python\")[1].split(\"```\")[0].strip()\n",
        "        elif \"```\" in code:\n",
        "            code = code.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "        # If no code was generated or request not suitable for Python\n",
        "        if not code or \"I cannot\" in code or \"I can't\" in code:\n",
        "            return {\n",
        "                \"messages\": [AIMessage(content=\"I'm not able to generate appropriate Python code for this request.\")],\n",
        "                \"next_agent\": \"end\"\n",
        "            }\n",
        "\n",
        "        # Execute the code safely (with restrictions)\n",
        "        allowed_modules = [\"math\", \"datetime\", \"random\", \"json\", \"collections\"]\n",
        "        exec_globals = {}\n",
        "\n",
        "        for module in allowed_modules:\n",
        "            try:\n",
        "                exec_globals[module] = __import__(module)\n",
        "            except ImportError:\n",
        "                pass\n",
        "\n",
        "        # Execute the code and capture output\n",
        "        try:\n",
        "            # Redirect stdout to capture print statements\n",
        "            from io import StringIO\n",
        "            import sys\n",
        "\n",
        "            old_stdout = sys.stdout\n",
        "            sys.stdout = captured_output = StringIO()\n",
        "\n",
        "            exec(code, exec_globals)\n",
        "\n",
        "            sys.stdout = old_stdout\n",
        "            result = captured_output.getvalue()\n",
        "\n",
        "            if not result:\n",
        "                result = \"Code executed successfully (no output)\"\n",
        "\n",
        "        except Exception as e:\n",
        "            result = f\"Error executing code: {str(e)}\"\n",
        "\n",
        "        response_text = f\"I executed the following Python code:\\n```python\\n{code}\\n```\\nResult:\\n{result}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        response_text = f\"Error in Python agent: {str(e)}\"\n",
        "\n",
        "    return {\n",
        "        \"messages\": [AIMessage(content=response_text)],\n",
        "        \"next_agent\": \"end\"\n",
        "    }\n",
        "\n",
        "# Coordinator Agent\n",
        "def coordinator_agent(state: AgentState):\n",
        "    \"\"\"Agent that decides which specialized agent to invoke\"\"\"\n",
        "    last_message = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
        "\n",
        "    # Use LLM to decide which agent to call with better prompting\n",
        "    prompt = f\"\"\"Analyze the user's request and decide which agent should handle it:\n",
        "\n",
        "User request: \"{last_message}\"\n",
        "\n",
        "Available agents:\n",
        "1. weather_agent - for weather-related queries (temperature, forecast, weather conditions, climate)\n",
        "2. python_agent - for calculations, data processing, math problems, or any request that can be solved with code\n",
        "\n",
        "Consider these examples:\n",
        "- \"What's the weather in Paris?\" â weather_agent\n",
        "- \"Calculate 5 * 8\" â python_agent\n",
        "- \"What's the temperature in Tokyo?\" â weather_agent\n",
        "- \"Write code to calculate factorial of 5\" â python_agent\n",
        "- \"How humid is it in London?\" â weather_agent\n",
        "- \"Solve 2x + 5 = 15\" â python_agent\n",
        "\n",
        "Respond with ONLY the name of the appropriate agent: either \"weather_agent\" or \"python_agent\"\n",
        "If the request doesn't match either, respond with \"end\".\"\"\"\n",
        "\n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    next_agent = response.content.strip().lower()\n",
        "\n",
        "    # Validate the response\n",
        "    if next_agent not in [\"weather_agent\", \"python_agent\"]:\n",
        "        next_agent = \"end\"\n",
        "\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"],\n",
        "        \"next_agent\": next_agent\n",
        "    }\n",
        "\n",
        "# Build the graph\n",
        "def build_agent_graph():\n",
        "    workflow = StateGraph(AgentState)\n",
        "\n",
        "    # Add nodes\n",
        "    workflow.add_node(\"coordinator\", coordinator_agent)\n",
        "    workflow.add_node(\"weather_agent\", weather_agent)\n",
        "    workflow.add_node(\"python_agent\", python_agent)\n",
        "\n",
        "    # Set entry point\n",
        "    workflow.set_entry_point(\"coordinator\")\n",
        "\n",
        "    # Add edges\n",
        "    workflow.add_conditional_edges(\n",
        "        \"coordinator\",\n",
        "        lambda state: state[\"next_agent\"],\n",
        "        {\n",
        "            \"weather_agent\": \"weather_agent\",\n",
        "            \"python_agent\": \"python_agent\",\n",
        "            \"end\": END\n",
        "        }\n",
        "    )\n",
        "\n",
        "    workflow.add_edge(\"weather_agent\", END)\n",
        "    workflow.add_edge(\"python_agent\", END)\n",
        "\n",
        "    return workflow.compile()\n",
        "\n",
        "# Create the graph\n",
        "agent_graph = build_agent_graph()\n",
        "\n",
        "# Function to run the agent system\n",
        "def run_agent_system(user_input: str):\n",
        "    \"\"\"Run the agent system with user input\"\"\"\n",
        "    initial_state = {\n",
        "        \"messages\": [HumanMessage(content=user_input)],\n",
        "        \"next_agent\": \"coordinator\"\n",
        "    }\n",
        "\n",
        "    result = agent_graph.invoke(initial_state)\n",
        "    return result[\"messages\"][-1].content\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    print(\"\\nð Agent Descriptions:\")\n",
        "    print(\"â¢ coordinator_agent: Analyzes user input and routes to appropriate agent\")\n",
        "    print(\"â¢ weather_agent: Fetches weather data from weatherapi.com\")\n",
        "    print(\"â¢ python_agent: Executes Python code for calculations\")\n",
        "    print(\"â¢ router: Conditional routing based on coordinator decision\")\n",
        "\n",
        "    print(\"\\nð§ª Testing the system:\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Test examples\n",
        "    test_queries = [\n",
        "        \"What's the weather in Sydney?\",\n",
        "        \"Can you calculate 5 * 8 for me?\",\n",
        "        \"What's the temperature in Tokyo?\",\n",
        "        \"Write Python code to calculate factorial of 5\",\n",
        "        \"How humid is it in London?\",\n",
        "        \"Solve for x: 2x + 5 = 15\"\n",
        "    ]\n",
        "\n",
        "    for query in test_queries:\n",
        "        print(f\"\\nð¤ User: {query}\")\n",
        "        response = run_agent_system(query)\n",
        "        print(f\"ð¤ Response: {response}\")\n",
        "        print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXx419Chyqlu",
        "outputId": "0748b0c9-5a35-45c0-cf31-b4d8bb44f4da"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ð Agent Descriptions:\n",
            "â¢ coordinator_agent: Analyzes user input and routes to appropriate agent\n",
            "â¢ weather_agent: Fetches weather data from weatherapi.com\n",
            "â¢ python_agent: Executes Python code for calculations\n",
            "â¢ router: Conditional routing based on coordinator decision\n",
            "\n",
            "ð§ª Testing the system:\n",
            "==================================================\n",
            "\n",
            "ð¤ User: What's the weather in Sydney?\n",
            "ð¤ Response: Weather in Sydney, Australia:\n",
            "- Temperature: 13.4Â°C\n",
            "- Condition: Light rain shower\n",
            "- Humidity: 77%\n",
            "- Wind Speed: 28.8 km/h\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "ð¤ User: Can you calculate 5 * 8 for me?\n",
            "ð¤ Response: I executed the following Python code:\n",
            "```python\n",
            "print(5 * 8)\n",
            "```\n",
            "Result:\n",
            "40\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "ð¤ User: What's the temperature in Tokyo?\n",
            "ð¤ Response: Weather in Tokyo, Japan:\n",
            "- Temperature: 23.8Â°C\n",
            "- Condition: Clear\n",
            "- Humidity: 46%\n",
            "- Wind Speed: 24.8 km/h\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "ð¤ User: Write Python code to calculate factorial of 5\n",
            "ð¤ Response: I executed the following Python code:\n",
            "```python\n",
            "def factorial(n):\n",
            "    if n == 0:\n",
            "        return 1\n",
            "    else:\n",
            "        return n * factorial(n-1)\n",
            "\n",
            "print(factorial(5))\n",
            "```\n",
            "Result:\n",
            "120\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "ð¤ User: How humid is it in London?\n",
            "ð¤ Response: Weather in London, United Kingdom:\n",
            "- Temperature: 14.1Â°C\n",
            "- Condition: Sunny\n",
            "- Humidity: 43%\n",
            "- Wind Speed: 17.6 km/h\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "ð¤ User: Solve for x: 2x + 5 = 15\n",
            "ð¤ Response: I executed the following Python code:\n",
            "```python\n",
            "from sympy import symbols, Eq, solve\n",
            "\n",
            "x = symbols('x')\n",
            "equation = Eq(2*x + 5, 15)\n",
            "solution = solve(equation, x)\n",
            "print(solution)\n",
            "```\n",
            "Result:\n",
            "[5]\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "31Lm8W0e0R6l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}